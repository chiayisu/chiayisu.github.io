---
title: "Natural Language Processing Fall 2021"
collection: teaching
type: "Graduate course"
permalink: /teaching/1-2021-fall-teaching
venue: "National Kaohsiung University of Science and Technology (Jiangong Campus)"
date: 2021-09-01
location: "City, Country"
---


## Course Description
The course mainly introduces the theories and application of dialogue system. We first introduce natural language understanding (NLU). Then, we will introduce the concepts of reinforcement learning (RL). Finally, we will give lectures on the applications of dialogue system if time-permitted.

## Lecture 0: Introduction to my Dialog System Research
* Note: **Will not upload PPT for this lecture**

## Lecture 1: Introduction to Natural Language Processing
* Lecture Slides: [PPT](https://docs.google.com/presentation/d/1tptz5D6BQ9QJRvnS7qbPiYQBS04wySSE/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/1-Q5wC-T1ecSsw8jbA1yJT9aC7_r0ieai/view?usp=sharing)
* Reading Materials
  1. [Can We Automate Scientific Reviewing?](https://arxiv.org/abs/2102.00176)
  2. [The Design and Implementation of XiaoIce, an Empathetic Social Chatbot](https://dl.acm.org/doi/10.1162/coli_a_00368)
  3. [Recipes for building an open-domain chatbot](https://arxiv.org/abs/2004.13637)
  4. [Semantically-Aligned Equation Generation for Solving and Reasoning MathWord Problems](https://www.aclweb.org/anthology/N19-1272/)
  5. [Stanza : A Python Natural Language Processing Toolkit for Many Human Languages](https://www.aclweb.org/anthology/2020.acl-demos.14/)
 
## Lecture 2: Distributed Representaion of Words
 * Lecture Slides: [PPT](https://docs.google.com/presentation/d/1xKvSX2zJQC0z1BuPcrYKMb7G7On_X9YO/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/1vlg-sCR4_UEr0JEAt-zDyQjmHLkXJBua/view?usp=sharing)
 * Reading Materials
   1. [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781)
   2. [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)
   3. [Stanford University CS224N Lecture1 (2019 Edition)](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/)

## Lecture 3: Advanced Word Vector and Introduction to Neural Network
* Lecture Slides: [PPT](https://docs.google.com/presentation/d/1KnpY12RB8eaoh_X6Ts_-r-Fw0dv6Td2f/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/1UU0XmZCb_7mZOkfuHIeyhHZA6WmZWbuB/view?usp=sharing)
* Reading Materials
  1. [GloVe: Global Vectors for Word Representation](https://www.aclweb.org/anthology/D14-1162/)
  2. [Speech and Language Processing: Information Extraction](https://web.stanford.edu/~jurafsky/slp3/) (Chapter number may vary according to the edition)
  3. [Stanford University CS224N Lecture2 and Lecture3 (2019 Edition)](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/) 

## Lecture 4: Backpropagation and Computation Graphs
* Lecture Slides: [PPT](https://docs.google.com/presentation/d/14JztTSqv2ueOb-4AjcQ8UXt3NvW5iVyq/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/107RowbVPtE65MNqKgjplPZz0Nyrpwa0-/view?usp=sharing)
* Reading Materials
  1. [Maxout Networks](https://arxiv.org/pdf/1302.4389.pdfMaxout%20Networks)
  2. [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)
  3. [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)
  4. [Adam: A Method for Stochastic Optimization](https://arxiv.org/pdf/1412.6980.pdf)
  5. [An overview of gradient descent optimization algorithms](https://arxiv.org/pdf/1609.04747.pdf)
  6. [Stanford University CS224N Lecture4 (2019 Edition)](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/)

## Lecture 5: Dependency Parsing
* Lecture Slides: [PPT](https://docs.google.com/presentation/d/1QmnOwWliA4UsDX2TlNZoll_feduDOGK7/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/1Y4zmOYnCqE1SGqwusuS9l5kEvY_Av5Uh/view?usp=sharing)
* Reading Materials
   1. [Incrementality in Deterministic Dependency Parsing](https://www.aclweb.org/anthology/W04-0308/)
   2. [Globally Normalized Transition-Based Neural Networks](https://arxiv.org/abs/1603.06042)
   3. [Fast and Robust Neural Network Joint Models for Statistical Machine Translation](https://www.aclweb.org/anthology/P14-1129/)
   4. [A Fast and Accurate Dependency Parser using Neural Networks](https://www.aclweb.org/anthology/D14-1082/)
   5. [Stanford University CS224N Lecture5 (2019 Edition)](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/)
* [Universal Dependency Parsing](https://universaldependencies.org/)

## Lecture 6: Recurrent Neural Networks and Language Models
* Lecture Slides: [PPT](https://docs.google.com/presentation/d/1zPjGRoYNbx6yLOQDIEoDeJL-3_R2Vy5b/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/1moONQvJA7MtkF7jrWbTjrbHSUNXnWmZ_/view?usp=sharing)
 * Reading Materials
   1. [Speech and Language Processing: N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/) (Chapter number may vary according to the edition)
   2. [Deep Visual-Semantic Alignments for Generating Image Descriptions](https://arxiv.org/abs/1412.2306)
   3. [Speechless? Here’s how AI learns to finish your sentences](https://tech.fb.com/speechless-heres-how-ai-learns-to-finish-your-sentences/)
   4. [Stanford University CS224N Lecture6 (2019 Edition)](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/)
   5. [Deep Learning - Sequence Modeling: Recurrent and Recursive Nets](https://www.deeplearningbook.org/)

## Lecture 7: Vanishing Gradients and Fancy RNNs
* Lecture Slides: [PPT](https://docs.google.com/presentation/d/14-laGM-JhLFysUtkNfM6nrNeQ8nIsHZ7/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/1f4XgFpyYk64V__iNF4Kghqn-ik41QqBf/view?usp=sharing)
* Reading Materials
  1. [On the difficulty of training Recurrent Neural Networks](https://arxiv.org/abs/1211.5063)
  2. [Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies](https://www.aclweb.org/anthology/Q16-1037/)
  3. [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)
  4. [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)
  5. [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)
  6. [Highway Networks](https://arxiv.org/abs/1505.00387)
  7. [Stanford University CS224N Lecture7 (2019 Edition)](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/)

## Lecture 8: Machine Translation, Seq2Seq, Attention, and Transformer
* Lecture Slides: [PPT](https://docs.google.com/presentation/d/1DiGPzhFnS9xplDbTPo9YvYpkrqZIRGpk/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/1lBmX4aagj8LLlEq-cTAjS9zpSnILMB0H/view?usp=sharing)
* Reading Materials
    1. [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
    2. [Attention Is All You Need](http://nlp.seas.harvard.edu/2018/04/03/attention.html) (Code Explanation)
    3. [Layer Normalization](https://arxiv.org/abs/1607.06450)
    4. [Universal Language Model Fine-tuning for Text Classification](https://aclanthology.org/P18-1031/)
    5. [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://aclanthology.org/N19-1423/)
    6. [BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://www.aclweb.org/anthology/2020.acl-main.703/)
    7. [Stanford University CS224N Lecture8 (2019 Edition)](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/)
    8. [Stanford University CS224N Lecture13 (2019 Edition)](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/)

## Lecture 9: Introduction to Reinforcement Learning
* Lecture Slides: [PPT](https://docs.google.com/presentation/d/1yFV6x3vaNYDLd1tjIFRqrTyraYVuGYZc/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/1AEOBbx-_oBipDA1fSUtm0m8fhSX62d3o/view?usp=sharing)
* Reading Materials
  1. [Introduction to Reinforcement Learning with David Silver Lecture1](https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver)
* Papers related to examples in lecture
  1. [Learning to Drive in a Day](https://arxiv.org/abs/1807.00412)
  2. [Deep Reinforcement Learning for Dialogue Generation](https://arxiv.org/abs/1606.01541)
  3. [Don’t Until the Final Verb Wait: Reinforcement Learning for Simultaneous Machine Translation](https://aclanthology.org/D14-1140/)
  4. [QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation](https://arxiv.org/abs/1806.10293)
  5. [Human-level control through deep reinforcement learning](https://www.nature.com/articles/nature14236?wm=book_wap_0005)

## Lecture 10: Markov Decision Processes
* Lecture Slides: [PPT](https://docs.google.com/presentation/d/17ycg4sXuZ0eS3hoUOWe6I6f8bE79eip6/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/1NLX7GcU9u-CgDIbUfo1dG_aGycmKNC_A/view?usp=sharing)
* Reading Materials
  1. [Introduction to Reinforcement Learning with David Silver Lecture2](https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver)

## Lecture 11: Planning by Dynamic Programming
* Lecture Slides: [PPT](https://docs.google.com/presentation/d/1SoDChXYUkTiZGzo3ITwVNtS6_Q1bPjn4/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/1t3xkzRB8sH6VuH5rMOiSZOjf4XJ7sHhW/view?usp=sharing)
* Reading Materials
  1. [Introduction to Reinforcement Learning with David Silver Lecture3](https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver)

## Lecture 12: Model-Free Prediction
* Lecture Slides: [PPT](https://docs.google.com/presentation/d/1frGqUtSnufxiJMysWgYxjo2M41DT9tQg/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/1IjKrb-IpQQrGNcRxw5tP8DaaLoLqmLnS/view?usp=sharing)
* Reading Materials
  1. [Introduction to Reinforcement Learning with David Silver Lecture4](https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver)

## Lecture 13: Model-Free Control
* Lecture Slides: [PPT](https://docs.google.com/presentation/d/1OHccT8YgfhC-3prALNlJV35i9OkgnvoX/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/1jl_JadUrUcYMo7qnODNZRttn1Dv4dUNF/view?usp=sharing)
* Reading Materials
  1. [Introduction to Reinforcement Learning with David Silver Lecture5](https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver)

## Lecture 14: Value Function Approximation
* Lecture Slides: [PPT](https://docs.google.com/presentation/d/1rmKN-BIKkGJ8j_SS0RLQjZDZbHT-SkST/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/1Y769SCXITfTOzVi04RbYApEEWG2ODnLd/view?usp=sharing)
* Reading Materials
  1. [Introduction to Reinforcement Learning with David Silver Lecture6](https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver)

## Lecture 15: Task Oriented Dialogue Systems & Multi-Modal Dialog System
* Lecture Slides: [PPT](https://docs.google.com/presentation/d/11f2EDsAGIPUQSDQ4L0u7OznhRaUEUB3i/edit?usp=sharing&ouid=114043367878486864741&rtpof=true&sd=true), [PDF](https://drive.google.com/file/d/1K20SnPiTsFqklK6Vell3y3WnzNR8yGqA/view?usp=sharing)
* Reading Materials
  1.  [Speech and Language Processing: Chatbots and Dialogue Systems](https://web.stanford.edu/~jurafsky/slp3/) (Chapter number may vary according to the edition)
  2.  [Continuously Learning Neural Dialogue Management](https://arxiv.org/abs/1606.02689)
  3.  [Sample-efficient Actor-Critic Reinforcement Learning with Supervised Data for Dialogue Management](https://arxiv.org/abs/1707.00130)
  4.  [Augment Information with Multimodal Information](https://visualqa.org/workshop_2020.html)

## Textbooks
* Natural Language Processing
  * Jurafsky and Martin, [Speech and Language Processing (3rd ed.)](https://web.stanford.edu/~jurafsky/slp3/)
* Deep Learning
  * Goodfellow, Bengio, and Courville, [Deep Learning](https://www.deeplearningbook.org/)
  * Zhang et al., [Dive into Deep Learning](https://d2l.ai/)
* Reinforcement Learning
  * Sutton and Barto, [Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book.html)
  * Vitay, [Deep Reinforcement Learning](https://julien-vitay.net/deeprl/)

## Online Courses
* Natural Language Processing and Deep Learning
  * [CS224n: Natural Language Processing with Deep Learning(2019 Edition)](http://web.stanford.edu/class/cs224n/)
* Reinforcement Learning
  * [Introduction to Reinforcement Learning with David Silver](https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver)
  * [Deep Reinforcement Learning](http://rail.eecs.berkeley.edu/deeprlcourse/)